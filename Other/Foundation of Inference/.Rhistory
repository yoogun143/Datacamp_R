mlbBat10 %>%
filter(AB >= 200) %>%
ggplot(aes(x = OBP, y = SLG)) +
geom_point()
# Identify the outlying player
mlbBat10 %>%
filter(AB >= 200, OBP < 0.2)
#### OUTLIER
# Original scatter plot
ggplot(mlbBat10, aes(x = OBP, y = SLG)) +
geom_point()
# Scatterplot of SLG vs. OBP
mlbBat10 %>%
filter(AB >= 200) %>%
ggplot(aes(x = OBP, y = SLG)) +
geom_point()
#### CORRELATION
# Compute correlation
ncbirths %>%
summarize(N = n(), r = cor(mage, weight))
# Compute correlation for all non-missing pairs
ncbirths %>%
summarize(N = n(), r = cor(weeks, weight, use = "pairwise.complete.obs"))
#### ANSCOMBE DATASET
# Compute properties of Anscombe
Anscombe %>%
group_by(set) %>%
summarize(N = n(), mean(x), sd(x), mean(y), sd(y), cor(x,y))
# Scatterplot with regression line
ggplot(data = bdims, aes(x = hgt, y = wgt)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
devtools::install_github("dgrtwo/gganimate")
library(gganimate)
# Update the static plot
p <- ggplot(Vocab, aes(x = education, y = vocabulary,
color = year, group = year,
frame = year, cumulative = TRUE)) +
stat_smooth(method = "lm", se = FALSE, size = 3)
library(car)
# Update the static plot
p <- ggplot(Vocab, aes(x = education, y = vocabulary,
color = year, group = year,
frame = year, cumulative = TRUE)) +
stat_smooth(method = "lm", se = FALSE, size = 3)
# Call gg_animate on p
x <- gg_animate(p, filename = "vocab.gif", interval = 1.0)
# Call gg_animate on p
x <- animate(p, filename = "vocab.gif", interval = 1.0)
ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, colour = country)) +
geom_point(alpha = 0.7, show.legend = FALSE) +
scale_colour_manual(values = country_colors) +
scale_size(range = c(2, 12)) +
scale_x_log10() +
facet_wrap(~continent) +
# Here comes the gganimate specific bits
labs(title = 'Year: {frame_time}', x = 'GDP per capita', y = 'life expectancy') +
transition_time(year) +
ease_aes('linear')
library(gapminder)
ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, colour = country)) +
geom_point(alpha = 0.7, show.legend = FALSE) +
scale_colour_manual(values = country_colors) +
scale_size(range = c(2, 12)) +
scale_x_log10() +
facet_wrap(~continent) +
# Here comes the gganimate specific bits
labs(title = 'Year: {frame_time}', x = 'GDP per capita', y = 'life expectancy') +
transition_time(year) +
ease_aes('linear')
gapminder
ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, colour = country)) +
geom_point(alpha = 0.7, show.legend = FALSE) +
scale_colour_manual(values = country_colors) +
scale_size(range = c(2, 12)) +
scale_x_log10() +
facet_wrap(~continent)
ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, colour = country)) +
geom_point(alpha = 0.7, show.legend = FALSE)
ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, colour = country)) +
geom_point(alpha = 0.7, show.legend = FALSE) +
scale_colour_manual(values = country_colors)
ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, colour = country)) +
geom_point(alpha = 0.7, show.legend = FALSE) +
scale_colour_manual(values = country_colors) +
scale_size(range = c(2, 12)) +
scale_x_log10() +
facet_wrap(~continent)
####
ggplot(mtcars, aes(factor(cyl), mpg)) +
geom_boxplot() +
# Here comes the gganimate code
transition_states(
gear,
transition_length = 2,
state_length = 1
) +
enter_fade() +
exit_shrink() +
ease_aes('sine-in-out')
mtcars
# Draw rectangle in null viewport
grid.rect(gp = gpar(fill = "grey90"))
library(grid)
# Draw rectangle in null viewport
grid.rect(gp = gpar(fill = "grey90"))
# Write text in null viewport
grid.text("null viewport")
# Draw a line
grid.lines(x = c(0, 0.75), y = c(0.25, 1),
gp = gpar(lty = 2, col = "red"))
# Create new viewport: vp
vp <- viewport(x = 0.5, y = 0.5, width = 0.5, height = 0.5, just = "center")
# Push vp
pushViewport(vp)
# Populate new viewport with rectangle
grid.rect(gp = gpar(fill = "blue"))
#### BUILD A PLOT FROM SCRATCH
# 1 - Create plot viewport: pvp
mar <- c(5, 4, 2, 2)
pvp <- plotViewport(mar)
# 2 - Push pvp
pushViewport(pvp)
# 3 - Add rectangle
grid.rect(gp = gpar(fill = "grey80"))
#### BUILD A PLOT FROM SCRATCH
# 1 - Create plot viewport: pvp
mar <- c(5, 4, 2, 2)
pvp <- plotViewport(mar)
# 2 - Push pvp
pushViewport(pvp)
# 3 - Add rectangle
grid.rect(gp = gpar(fill = "grey80"))
# Create data viewport: dvp
dvp <- dataViewport(xData = mtcars$wt, yData = mtcars$mpg)
# 4 - Push dvp
pushViewport(dvp)
# Add two axes
grid.xaxis()
grid.yaxis()
# 1 - Add text to x axis
grid.text("Weight", y = unit(-3, "lines"))
# 2 - Add text to y axis
grid.text("MPG", x = unit(-3, "lines"), rot = 90)
# 3 - Add points
grid.points(x = mtcars$wt, y = mtcars$mpg, pch = 16)
# 1 - Add text to x axis
grid.text("Weight", y = unit(-3, "lines"), name = "xaxis")
# 2 - Add text to y axis
grid.text("MPG", x = unit(-3, "lines"), rot = 90, name = "yaxis")
# 3 - Add points
grid.points(x = mtcars$wt, y = mtcars$mpg, pch = 16, name = "datapoints")
# Edit "xaxis"
grid.edit("xaxis", label = "Weight (1000 lbs)")
#### BUILD A PLOT FROM SCRATCH
# 1 - Create plot viewport: pvp
mar <- c(5, 4, 2, 2)
pvp <- plotViewport(mar)
# 2 - Push pvp
pushViewport(pvp)
# 3 - Add rectangle
grid.rect(gp = gpar(fill = "grey80"))
# Create data viewport: dvp
dvp <- dataViewport(xData = mtcars$wt, yData = mtcars$mpg)
# 4 - Push dvp
pushViewport(dvp)
# Add two axes
grid.xaxis()
grid.yaxis()
# 1 - Add text to x axis
grid.text("Weight", y = unit(-3, "lines"), name = "xaxis")
# 2 - Add text to y axis
grid.text("MPG", x = unit(-3, "lines"), rot = 90, name = "yaxis")
# 3 - Add points
grid.points(x = mtcars$wt, y = mtcars$mpg, pch = 16, name = "datapoints")
# Edit "xaxis"
grid.edit("xaxis", label = "Weight (1000 lbs)")
# Edit "yaxis"
grid.edit("yaxis", label = "Miles/(US) gallon")
# Edit "datapoints"
grid.edit("datapoints", gp = gpar(col = "#C3212766", cex = 2))
#### GTABLE
# A simple plot p
p <- ggplot(mtcars, aes(x = wt, y = mpg, col = factor(cyl))) + geom_point()
# Create gtab with ggplotGrob()
gtab <- ggplotGrob(p)
# Print out gtab
gtab
# Extract the grobs from gtab: gtab
g <- gtab$grobs
# Draw only the legend
legend_index <- which(vapply(g, inherits, what = "gtable", logical(1)))
grid.draw(g[[legend_index]])
g
g[[legend_index]]
# Print out gtab
gtab
g
# 1 - Show layout of legend grob
gtable_show_layout(g[[legend_index]])
#### GTABLE: GRAPHICAL OBJECT (GROB)
library(gtable)
# 1 - Show layout of legend grob
gtable_show_layout(g[[legend_index]])
grid.draw(g[[legend_index]])
# Create text grob
my_text <- textGrob(label = "Motor Trend, 1974", gp = gpar(fontsize = 7, col = "gray25"))
# 1 - Show layout of legend grob
gtable_show_layout(g[[legend_index]])
# 2 - Use gtable_add_grob to modify original gtab
new_legend <- gtable_add_grob(gtab$grobs[[legend_index]], my_text, 3, 2)
# 3 - Update in gtab
gtab$grobs[[legend_index]] <- new_legend
# 4 - Draw gtab
grid.draw(gtab)
#### GTABLE: GRAPHICAL OBJECT TABLE (GROB)
library(gtable)
# A simple plot p
p <- ggplot(mtcars, aes(x = wt, y = mpg, col = factor(cyl))) + geom_point()
# Create gtab with ggplotGrob()
gtab <- ggplotGrob(p)
# Print out gtab
gtab
# Extract the grobs from gtab: gtab
g <- gtab$grobs
# Draw only the legend
legend_index <- which(vapply(g, inherits, what = "gtable", logical(1)))
grid.draw(g[[legend_index]])
# 1 - Show layout of legend grob
gtable_show_layout(g[[legend_index]])
# Create text grob
my_text <- textGrob(label = "Motor Trend, 1974", gp = gpar(fontsize = 7, col = "gray25"))
# 2 - Use gtable_add_grob to modify original gtab
new_legend <- gtable_add_grob(gtab$grobs[[legend_index]], my_text, 3, 2)
# 3 - Update in gtab
gtab$grobs[[legend_index]] <- new_legend
# 4 - Draw gtab
grid.draw(gtab)
# 1 - Show layout of legend grob
gtable_show_layout(g[[legend_index]])
# Create text grob
my_text <- textGrob(label = "Motor Trend, 1974", gp = gpar(fontsize = 7, col = "gray25"))
# 2 - Use gtable_add_grob to modify original gtab
new_legend <- gtable_add_grob(gtab$grobs[[legend_index]], my_text, 3, 2)
# 3 - Update in gtab
gtab$grobs[[legend_index]] <- new_legend
View(gtab)
View(gtab)
gtab
gtab$grobs
gtab$grobs[[legend_index]]
# 4 - Draw gtab
grid.draw(gtab)
#### GGPLOT OBJECT
# Simple plot p
p <- ggplot(mtcars, aes(x = wt, y = mpg, col = factor(cyl))) + geom_point()
# Examine class() and names()
class(p)
names(p)
# Print the scales sub-list
p$scales$scales
# Update p
p <- p +
scale_x_continuous("Length", limits = c(4, 8), expand = c(0, 0)) +
scale_y_continuous("Width", limits = c(2, 4.5), expand = c(0, 0))
# Print the scales sub-list
p$scales$scales
#### GGPLOT_BUILD AND GGPLOT_GTABLE
# Box plot of mtcars: p
p <- ggplot(mtcars, aes(x = factor(cyl), y = wt)) + geom_boxplot()
# Create pbuild
pbuild <- ggplot_build(p)
# a list of 3 elements
names(pbuild)
# Print out each element in pbuild
pbuild$data
pbuild$layout
pbuild$plot
pbuild$panel
# Create gtab from pbuild
gtab <- ggplot_gtable(pbuild)
# Draw gtab
grid.draw(gtab)
# Build pdata
pdata <- ggplot_build(p)$data
# confirm that the first element of the list is a data frame
class(pdata[[1]])
# Isolate this data frame
my_df <- pdata[[1]]
# The x labels
my_df$group <- c("4", "6", "8")
# Print out specific variables
my_df[c(1:6, 11)]
#### GRID EXTRA
# Add a theme (legend at the bottom)
g1 <- ggplot(mtcars, aes(wt, mpg, col = cyl)) +
geom_point(alpha = 0.5) +
theme(legend.position = "bottom")
# Add a theme (no legend)
g2 <- ggplot(mtcars, aes(disp, fill = cyl)) +
geom_histogram(position = "identity", alpha = 0.5, binwidth = 20) +
theme(legend.position = "none")
# Load gridExtra
library(gridExtra)
# Call grid.arrange()
grid.arrange(g1, g2, ncol = 2)
#### GRID EXTRA = MFROW
# Definitions of g1 and g2
g1 <- ggplot(mtcars, aes(wt, mpg, col = cyl)) +
geom_point() +
theme(legend.position = "bottom")
g2 <- ggplot(mtcars, aes(disp, fill = cyl)) +
geom_histogram(binwidth = 20) +
theme(legend.position = "none")
# Extract the legend from g1
my_legend <- ggplotGrob(g1)$grobs[[legend_index]]
# Create g1_noleg
g1_noleg <- g1 +
theme(legend.position = "none")
# Calculate the height: legend_height
legend_height <- sum(my_legend$heights)
# Arrange g1_noleg, g2 and my_legend
grid.arrange(g1_noleg, g2, my_legend,
layout_matrix = matrix(c(1, 3, 2, 3), ncol = 2),
heights = unit.c(unit(1, "npc") - legend_height, legend_height))
setwd("E:/Datacamp/R/Other/Foundation of Inference")
setwd("E:/Datacamp/R/Other/Foundation of Inference")
load('all_polls.RData')
#### RESAMPLING FROM A SAMPLE
# Select one poll from which to resample: one_poll
one_poll <- all_polls %>%
filter(poll == 1) %>%
select(vote)
library(dplyr)
#### RESAMPLING FROM A SAMPLE
# Select one poll from which to resample: one_poll
one_poll <- all_polls %>%
filter(poll == 1) %>%
select(vote)
View(one_poll)
View(all_polls)
# Generate 1000 resamples of one_poll: one_poll_boot_30
one_poll_boot_30 <- one_poll %>%
rep_sample_n(size = 30, replace = TRUE, reps = 1000)
homes %>%
rep_sample_n(size = nrow(homes), reps = 10)
# Define function create a new replicate column
rep_sample_n <- function (tbl, size, replace = FALSE, reps = 1)
{
n <- nrow(tbl)
i <- unlist(replicate(reps, sample.int(n, size, replace = replace),
simplify = FALSE))
rep_tbl <- cbind(replicate = rep(1:reps, rep(size, reps)),
tbl[i, ])
dplyr::group_by(rep_tbl, replicate)
}
# Generate 1000 resamples of one_poll: one_poll_boot_30
one_poll_boot_30 <- one_poll %>%
rep_sample_n(size = 30, replace = TRUE, reps = 1000)
# Compute p-hat for each poll: ex1_props
ex1_props <- all_polls %>%
group_by(poll) %>%
summarize(prop_yes = mean(vote))
# Compute p-hat* for each resampled poll: ex2_props
ex2_props <- one_poll_boot_30 %>%
summarize(prop_yes = mean(vote))
# Compare variability of p-hat and p-hat*
ex1_props %>% summarize(sd(prop_yes))
ex2_props %>% summarize(sd(prop_yes))
####
# Resample from one_poll with n = 3: one_poll_boot_3
one_poll_boot_3 <- one_poll %>%
rep_sample_n(3, replace = TRUE, reps = 1000)
# Resample from one_poll with n = 300: one_poll_boot_300
one_poll_boot_300 <- one_poll %>%
rep_sample_n(300, replace = TRUE, reps = 1000)
# Compute p-hat* for each resampled poll: ex3_props
ex3_props <- one_poll_boot_3 %>%
summarize(prop_yes = mean(vote))
# Compute p-hat* for each resampled poll: ex4_props
ex4_props <- one_poll_boot_300 %>%
summarize(prop_yes = mean(vote))
# Compare variability of p-hat* for n = 3 vs. n = 300
ex3_props %>% summarize(sd(prop_yes))
ex4_props %>% summarize(sd(prop_yes))
####
# Recall the variability of sample proportions
ex1_props %>% summarize(sd(prop_yes))
ex2_props %>% summarize(sd(prop_yes))
ex3_props %>% summarize(sd(prop_yes))
ex4_props %>% summarize(sd(prop_yes))
# Create smoothed density curves for all four experiments
ggplot() +
geom_density(data = ex1_props, aes(x = prop_yes), col = "black", bw = .1) +
geom_density(data = ex2_props, aes(x = prop_yes), col = "green", bw = .1) +
geom_density(data = ex3_props, aes(x = prop_yes), col = "red", bw = .1) +
geom_density(data = ex4_props, aes(x = prop_yes), col = "blue", bw = .1)
#### VISUALIZE P-HAT
library(ggplot2)
# Create smoothed density curves for all four experiments
ggplot() +
geom_density(data = ex1_props, aes(x = prop_yes), col = "black", bw = .1) +
geom_density(data = ex2_props, aes(x = prop_yes), col = "green", bw = .1) +
geom_density(data = ex3_props, aes(x = prop_yes), col = "red", bw = .1) +
geom_density(data = ex4_props, aes(x = prop_yes), col = "blue", bw = .1)
#### EMPIRICAL RULE
# Compute proportion of votes for Candidate X: props
props <- all_polls %>%
group_by(poll) %>%
summarize(prop_yes = mean(vote == 1))
# Proportion of polls within 2SE
props %>%
mutate(lower = mean(prop_yes) - 2 * sd(prop_yes),
upper = mean(prop_yes) + 2 * sd(prop_yes),
in_CI = prop_yes > lower & prop_yes < upper) %>%
summarize(mean(in_CI))
View(props)
####
# Again, set the one sample that was collected
one_poll <- all_polls %>%
filter(poll == 1) %>%
select(vote)
# Compute p-hat from one_poll: p_hat
p_hat <- mean(one_poll$vote)
# Bootstrap to find the SE of p-hat: one_poll_boot
one_poll_boot <- one_poll %>%
rep_sample_n(30, replace = TRUE, reps = 1000) %>%
summarize(prop_yes_boot = mean(vote == 1))
# Create an interval of plausible values
one_poll_boot %>%
summarize(lower = p_hat - 2 * sd(one_poll_boot$prop_yes_boot),
upper = p_hat + 2 * sd(one_poll_boot$prop_yes_boot))
#### BOOTSTRAP PERCENTILE INTERVAL
# Find the 2.5% and 97.5% of the p-hat values
one_poll_boot %>%
summarize(q025_prop = quantile(prop_yes_boot, p = 0.025),
q975_prop = quantile(prop_yes_boot, p = 0.975))
# Bootstrap t-confidence interval for comparison
one_poll_boot %>%
summarize(lower = p_hat - 2*sd(one_poll_boot$prop_yes_boot),
upper = p_hat + 2*sd(one_poll_boot$prop_yes_boot))
#### SAMPLE SIZE ON BOOTSTRAP CIS
# Recall the bootstrap t-confidence interval
p_hat <- mean(one_poll$vote)
one_poll_boot %>%
summarize(lower = p_hat - 2 * sd(prop_yes_boot),
upper = p_hat + 2 * sd(prop_yes_boot))
# Collect a sample of 30 observations from the population
one_poll <- as.tbl(data.frame(vote = rbinom(30, 1, .6)))
# Resample the data using samples of size 300 (an incorrect strategy!)
one_poll_boot_300 <- one_poll %>%
rep_sample_n(300, replace = TRUE, reps = 1000) %>%
summarize(prop_yes_boot = mean(vote))
# Find the endpoints of the bootstrap t-confidence interval
one_poll_boot_300 %>%
summarize(lower = p_hat - 2 * sd(prop_yes_boot),
upper = p_hat + 2 * sd(prop_yes_boot))
# Resample the data using samples of size 3 (an incorrect strategy!)
one_poll_boot_3 <- one_poll %>%
rep_sample_n(3, replace = TRUE, reps = 1000) %>%
summarize(prop_yes_boot = mean(vote))
# Find the endpoints of the the bootstrap t-confidence interval
one_poll_boot_3 %>%
summarize(lower = p_hat - 2 * sd(prop_yes_boot),
upper = p_hat + 2 * sd(prop_yes_boot))
one_poll_boot %>%
summarize(lower = p_hat - 2 * sd(prop_yes_boot),
upper = p_hat + 2 * sd(prop_yes_boot))
# Collect a sample of 30 observations from the population
one_poll <- as.tbl(data.frame(vote = rbinom(30, 1, .6)))
# Resample the data using samples of size 300 (an incorrect strategy!)
one_poll_boot_300 <- one_poll %>%
rep_sample_n(300, replace = TRUE, reps = 1000) %>%
summarize(prop_yes_boot = mean(vote))
# Find the endpoints of the bootstrap t-confidence interval
one_poll_boot_300 %>%
summarize(lower = p_hat - 2 * sd(prop_yes_boot),
upper = p_hat + 2 * sd(prop_yes_boot))
# Resample the data using samples of size 3 (an incorrect strategy!)
one_poll_boot_3 <- one_poll %>%
rep_sample_n(3, replace = TRUE, reps = 1000) %>%
summarize(prop_yes_boot = mean(vote))
# Find the endpoints of the the bootstrap t-confidence interval
one_poll_boot_3 %>%
summarize(lower = p_hat - 2 * sd(prop_yes_boot),
upper = p_hat + 2 * sd(prop_yes_boot))
#### SAMPLE PROPORTION VALUE EFFECTS ON BOOTSTRAP CIS
# Collect 30 observations from a population with true proportion of 0.8
one_poll <- as.tbl(data.frame(vote = rbinom(n = 30, size = 1, prob = 0.8)))
# Compute p-hat of new sample: p_hat
p_hat <- mean(one_poll$vote)
# Resample the 30 observations (with replacement)
one_poll_boot <- one_poll %>%
rep_sample_n(30, replace = TRUE, reps = 1000) %>%
summarize(prop_yes_boot = mean(vote))
# Calculate the bootstrap t-confidence interval
one_poll_boot %>%
summarize(lower = p_hat - 2 * sd(one_poll_boot$prop_yes_boot),
upper = p_hat + 2 * sd(one_poll_boot$prop_yes_boot))
#### PERCENTILE EFFECTS ON BOOTSTRAP CIS
# Calculate a 95% bootstrap percentile interval
one_poll_boot %>%
summarize(q025_prop = quantile(prop_yes_boot, p = .025),
q975_prop = quantile(prop_yes_boot, p = .975))
# Calculate a 99% bootstrap percentile interval
one_poll_boot %>%
summarize(q005_prop = quantile(prop_yes_boot, p = .005),
q995_prop = quantile(prop_yes_boot, p = .995))
# Calculate a 90% bootstrap percentile interval
one_poll_boot %>%
summarize(q05_prop = quantile(prop_yes_boot, p = .05),
q95_prop = quantile(prop_yes_boot, p = .95))
